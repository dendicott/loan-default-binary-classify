{"cells":[{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# import necessary libraries\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import preprocessing\n","from sklearn.metrics import f1_score, log_loss\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["class BinaryClassification:\n","    def __init__(self, df, target):\n","        self.df = df.copy()\n","        self.target_label = target\n","        self.target = np.array(df[target])\n","    \n","    def preprocess_drop(self, ignore_list=[]):\n","        \"\"\"Takes a list of columns the user wants to drop from\n","        from the dataframe before fitting the model. This will\n","        automatically include the target.\n","\n","        Args:\n","            ignore_list (list): list of column names as strings to be removed from dataset\n","        Returns:\n","            None: dataframe copy is modified in place\n","        \"\"\"\n","        # append the target to list of columsn to remove\n","        ignore_list.append(self.target_label)\n","        \n","        # drop each column in ignore_list on the y-axis, modified in-place\n","        self.df.drop(columns=ignore_list,axis=1,inplace=True)\n","    \n","    \n","    def preprocess_encode(self):\n","        \"\"\"Uses sklearn LabelEncode to convert categorical data to numeric\n","            for use in model. \n","            \n","        Return:\n","            None : encoding done in place on DataFrame\n","        \"\"\"\n","        # Initialize label encoder object\n","        label_encode = preprocessing.LabelEncoder()\n","        \n","        # Loop across each column in the dataset\n","        for col in self.df.columns:\n","            # Check that column data is not int64 or float64, not necessary to encode \n","            if self.df.dtypes[col] != 'int64' and self.df.dtypes[col] != 'float64':\n","                # Encode all categorical data for use in model\n","                self.df[col] = label_encode.fit_transform(self.df[col])\n","        \n","        # self.df = pd.get_dummies(self.df)       \n","    \n","    def preprocess_split(self):\n","        \"\"\"Takes input dataframe and target array and splits\n","            into training and validation data using train_test_split\n","            from sklearn. Function takes no input, and generates the\n","            split data sets for training and testing.\n","        \n","        Return:\n","            None: generates train/valid datasets in place on class\n","        \"\"\"\n","        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(self.df,self.target,\n","                                                                                    train_size=0.7,\n","                                                                                    test_size=0.3,\n","                                                                                    random_state=0)\n","    \n","    def preprocess_impute(self):\n","        \"\"\"Uses sklearn SimpleImputer() to fill in\n","            null data. Should be used on predictor dataset\n","            after being split by train_test_split.\n","            \n","        Return:\n","            None: training and validation predictors imputed in place\n","        \"\"\"\n","        # Create imputer instance\n","        dataImpute = SimpleImputer()\n","        \n","        # Run imputer on training dataset, and transform on validation dataset\n","        self.X_train_imputed = pd.DataFrame(dataImpute.fit_transform(self.X_train))\n","        self.X_valid_imputed = pd.DataFrame(dataImpute.transform(self.X_valid))\n","        \n","        # Add columns back in that are removed in SimpleImputer\n","        self.X_train_imputed.columns = self.X_train.columns\n","        self.X_valid_imputed.columns = self.X_valid.columns\n","    \n","\n","    def preprocess(self, ignore_list=[]):\n","        \"\"\"Serves as a wrapper for all preprocessing methods. Calls\n","            preprocessing steps in correct order for model preparation.\n","            Performs the following:\n","                1. preprocess_drop: removes columns you don't want to use in the model, removes target\n","                2. preprocess_encode: convert categorical data into numeric for impute and modeling\n","                3. preprocess_split: splits dataset into training and validation data\n","                4. preprocess_impute: impute predictor datasets\n","\n","        Args:\n","            ignore_list (list, optional): _description_. Defaults to [].\n","        \"\"\"\n","        self.preprocess_drop(params_to_ignore)\n","        self.preprocess_encode()\n","        self.preprocess_split()\n","        self.preprocess_impute()\n","    \n","    def fit(self, X, y):\n","        \"\"\"This function fits a given set of predictors and target to the model.\n","\n","        Args:\n","            X (pd.DataFrame): Input feature predictors for the model\n","            y (np.ndarry): Array of target for model\n","        Returns:\n","            None\n","        \"\"\"\n","        self.model = LogisticRegression(tol=0.0001,\n","                                        solver='liblinear',\n","                                        max_iter=5000,\n","                                        random_state=0,\n","                                        class_weight={0: 0.2, 1: 0.8})\n","        self.model.fit(X, y)\n","        \n","    \n","    def predict(self, X):\n","        \"\"\"Generates prediction from Logistic Regression model\n","            on a given predictor dataset. Returns ndarray of\n","            prediction data.\n","\n","        Args:\n","            X (pd.DataFrame): Predictor dataset to make a prediction on\n","        Returns:\n","            y_pred (np.array): ndarray of prediction data from Logistic Regression\n","        \"\"\"\n","        \n","        self.y_pred = self.model.predict(X)\n","        \n","        return(self.y_pred)\n","    \n","    def predict_proba(self, X):\n","        \"\"\"Given a predictor dataset, calculates the probability matrix for \n","            Logistic Regression model using sklearn predict_proba method.\n","\n","        Args:\n","            X (pd.DataFrame): Predictor dataset to predict target probability\n","            \n","        Return:\n","            y_pred_proba (np.array): Probability maxtrix for the Logistic Regression prediction\n","        \"\"\"\n","        \n","        self.y_pred_proba = self.model.predict_proba(X)\n","        \n","        return(self.y_pred_proba)\n","        \n","    def evaluate(self, X, y):\n","        \"\"\"Evaluates F1 score and log loss for the Logistic regression\n","            model.\n","\n","        Args:\n","            X (pd.DataFrame): Input predictor dataset\n","            y (np.ndarray): Ground truth labels as a numpy array of 0-s and 1-s\n","        Returns:\n","            eval_dict (dict): dictionary containing f1_score and logloss result\n","        \"\"\"\n","        self.f1_score = f1_score(y, self.y_pred)\n","        self.logloss = log_loss(y, self.y_pred)\n","        \n","        eval_dict = {'f1_score':self.f1_score,'logloss':self.logloss}\n","                \n","        return(eval_dict)\n","    \n","    def tune_parameters(self, X, y):\n","        \"\"\"Using the predictor DataFrame and ground truth array, will\n","            return the optimal choice for the following parameters\n","            maximizing for F1 score in LogisticRegression:\n","                -solver (possible solvers for LogisticRegression)\n","                -tol (stopping criteria tolerance)\n","                -fit_intercept (intercept added to decision function)\n","                -class_weights (Weights associated with classes in the form {class_label: weight})\n","                -scores (post-tuning metrics for f1 and logloss)\n","\n","        Args:\n","            X (pd.DataFrame): Input predictor dataset\n","            y (np.ndarray):  Ground truth labels as a numpy array of 0-s and 1-s.\n","        Returns:\n","            tuned_params (dict): Output the average scores across all CV validation partitions and best parameters\n","        \"\"\"\n","        \n","        # Tuning for optimal LogisticRegression\n","        #   solver using sklearn cross_val_score\n","        tuned_params = {}\n","\n","        solver = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n","        solver_score = {}\n","\n","        for x in solver:\n","\n","            my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n","                                        ('model', LogisticRegression(solver=x, class_weight='balanced'))])\n","\n","            scores = cross_val_score(my_pipeline, X, y,\n","                                    cv=5, scoring='f1')\n","\n","            solver_score[x] = scores.mean()\n","\n","        tuned_params['solver'] = max(solver_score, key=solver_score.get)\n","        # END OF solver tuning\n","\n","        # Tuning for stopping criteria tolerance\n","        #   using sklearn cross_val_score\n","        tolerance = np.linspace(0.0001, 0.1, 10)\n","        tol_score = {}\n","        for x in tolerance:\n","\n","            my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n","                                        ('model', LogisticRegression(tol=x, solver=tuned_params['solver'],\n","                                                                    class_weight='balanced'))])\n","\n","            scores = cross_val_score(my_pipeline, X, y,\n","                                    cv=5, scoring='f1')\n","\n","            tol_score[x] = scores.mean()\n","\n","        tuned_params['tol'] = max(tol_score, key=tol_score.get)\n","        # END OF tol tuning\n","        \n","        # Tuning for decision function fit_intercept\n","        #   using sklearn cross_val_score\n","        fit_intercept = [True, False]\n","        fit_int_score = {}\n","\n","        for x in fit_intercept:\n","            my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n","                                        ('model', LogisticRegression(\n","                                            fit_intercept=x,\n","                                            tol=tuned_params['tol'],\n","                                            solver=tuned_params['solver'],\n","                                            class_weight='balanced'))])\n","\n","            scores = cross_val_score(my_pipeline, X, y,\n","                                    cv=5, scoring='f1')\n","\n","            fit_int_score[x] = scores.mean()\n","\n","        tuned_params['fit_intercept'] = max(fit_int_score, key=fit_int_score.get)\n","        # END OF fit_intercept tuning\n","        \n","        # Tuning for LogisticRegression class_weight\n","        #   using sklearn cross_val_score\n","        class_zero_weights = np.linspace(0.0,0.99,50)\n","        weights_score = {}\n","\n","        for x in class_zero_weights:\n","            my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n","                                        ('model', LogisticRegression(\n","                                            fit_intercept=tuned_params['fit_intercept'],\n","                                            tol=tuned_params['tol'],\n","                                            solver=tuned_params['solver'],\n","                                            class_weight={0: x, 1: 1-x}))])\n","\n","            scores = cross_val_score(my_pipeline, X, y,\n","                                    cv=5, scoring='f1')\n","\n","            weights_score[x] = scores.mean()\n","\n","        class_zero_weight_max = max(weights_score, key=weights_score.get)\n","\n","        tuned_params['class_weight'] = {0: class_zero_weight_max,1:1-class_zero_weight_max}\n","        # END OF class_weight tuning\n","        \n","        # Scoring metrics f1 and logloss post-tuning\n","        #   using sklearn cross_val_score\n","        metrics = ['f1', 'neg_log_loss']\n","        metrics_score = {}\n","\n","        for x in metrics:\n","            my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n","                                        ('model', LogisticRegression(\n","                                            fit_intercept=tuned_params['fit_intercept'],\n","                                            tol=tuned_params['tol'],\n","                                            solver=tuned_params['solver'],\n","                                            class_weight=tuned_params['class_weight']))])\n","\n","            scores = cross_val_score(my_pipeline, X, y,\n","                                    cv=5, scoring=x)\n","\n","            metrics_score[x] = abs(scores.mean())\n","\n","            if x == 'f1':\n","                metrics_score['f1_score'] = metrics_score.pop('f1')\n","            elif x == 'neg_log_loss':\n","                metrics_score['logloss'] = metrics_score.pop('neg_log_loss')\n","\n","        tuned_params['scores'] = metrics_score\n","        # END OF performance metrics\n","        \n","        return(tuned_params)\n","        "]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["## USER INPUT\n","# list of parameters to remove from model based on preliminary data exploration\n","params_to_ignore = ['mths_since_last_delinq', 'mths_since_last_record',\n","                  'open_acc', 'mths_since_last_major_derog', 'initial_list_status',\n","                    'pymnt_plan', 'collections_12_mths_ex_med']\n","\n","# URL for dataset\n","data_url = 'https://s3.amazonaws.com/datarobot_public_datasets/DR_Demo_Lending_Club_reduced.csv'\n","\n","# Read dataset into pandas DataFrame\n","lending_data = pd.read_csv(data_url, index_col='Id')\n","\n","# Select the target from dataset columns, string must match column label exactly\n","target = 'is_bad'\n","\n","# Initialize the class to creat model\n","classify = BinaryClassification(lending_data, target)\n","## END OF USER INPUT\n","\n","# Model method calls\n","classify.preprocess(params_to_ignore)\n","classify.fit(classify.X_train_imputed,classify.y_train)\n","predictions = classify.predict(classify.X_valid_imputed)\n","predict_proba = classify.predict_proba(classify.X_valid_imputed)\n","evaluate = classify.evaluate(classify.X_valid_imputed,classify.y_valid)\n","tune = classify.tune_parameters(classify.X_train_imputed,classify.y_train)\n","#classify.X_train_imputed.head()\n","\n","predict_df = pd.DataFrame()\n","predict_df['Prediction'] = classify.y_pred\n","predict_df['Validation'] = classify.y_valid\n","\n","path = os.getcwd() + '.csv'\n","predict_df.to_csv(path)\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model output array:\n","[0 0 0 ... 0 0 0]\n","\n","\n","Model probability matrix:\n","[[0.5102287  0.4897713 ]\n"," [0.63540809 0.36459191]\n"," [0.77961369 0.22038631]\n"," ...\n"," [0.69465588 0.30534412]\n"," [0.69192859 0.30807141]\n"," [0.59705987 0.40294013]]\n","\n","\n","Model evaluation criteria:\n","{'f1_score': 0.20558002936857564, 'logloss': 6.2285555782134026}\n","\n","\n","Model tuning results:\n","{'solver': 'newton-cg', 'tol': 0.0001, 'fit_intercept': False, 'class_weight': {0: 0.12122448979591836, 1: 0.8787755102040816}, 'scores': {'f1_score': 0.27064069722350786, 'logloss': 0.7009417227041075}}\n"]}],"source":["print(\"Model output array:\")\n","print(predictions)\n","print('\\n')\n","print(\"Model probability matrix:\")\n","print(predict_proba)\n","print('\\n')\n","print(\"Model evaluation criteria:\")\n","print(evaluate)\n","print('\\n')\n","print(\"Model tuning results:\")\n","print(tune)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["<matplotlib.legend.Legend at 0x7fd3c467c290>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.hist(predict_df,label=predict_df.columns)\n","plt.legend()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["0.20558002936857564"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["classify.f1_score"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>is_bad</th>\n","      <th>emp_length</th>\n","      <th>home_ownership</th>\n","      <th>annual_inc</th>\n","      <th>verification_status</th>\n","      <th>pymnt_plan</th>\n","      <th>purpose_cat</th>\n","      <th>zip_code</th>\n","      <th>addr_state</th>\n","      <th>debt_to_income</th>\n","      <th>...</th>\n","      <th>mths_since_last_record</th>\n","      <th>open_acc</th>\n","      <th>pub_rec</th>\n","      <th>revol_bal</th>\n","      <th>revol_util</th>\n","      <th>total_acc</th>\n","      <th>initial_list_status</th>\n","      <th>collections_12_mths_ex_med</th>\n","      <th>mths_since_last_major_derog</th>\n","      <th>policy_code</th>\n","    </tr>\n","    <tr>\n","      <th>Id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>MORTGAGE</td>\n","      <td>NaN</td>\n","      <td>not verified</td>\n","      <td>n</td>\n","      <td>medical</td>\n","      <td>766xx</td>\n","      <td>TX</td>\n","      <td>10.87</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>12087</td>\n","      <td>12.1</td>\n","      <td>44.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>PC4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>RENT</td>\n","      <td>NaN</td>\n","      <td>not verified</td>\n","      <td>n</td>\n","      <td>debt consolidation</td>\n","      <td>660xx</td>\n","      <td>KS</td>\n","      <td>9.15</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>10114</td>\n","      <td>64.0</td>\n","      <td>5.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>PC1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>RENT</td>\n","      <td>NaN</td>\n","      <td>not verified</td>\n","      <td>n</td>\n","      <td>credit card</td>\n","      <td>916xx</td>\n","      <td>CA</td>\n","      <td>11.24</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>81</td>\n","      <td>0.6</td>\n","      <td>8.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>PC4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>MORTGAGE</td>\n","      <td>NaN</td>\n","      <td>not verified</td>\n","      <td>n</td>\n","      <td>debt consolidation</td>\n","      <td>124xx</td>\n","      <td>NY</td>\n","      <td>6.18</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>6.0</td>\n","      <td>0.0</td>\n","      <td>10030</td>\n","      <td>37.1</td>\n","      <td>23.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>PC2</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>MORTGAGE</td>\n","      <td>NaN</td>\n","      <td>VERIFIED - income</td>\n","      <td>n</td>\n","      <td>debt consolidation</td>\n","      <td>439xx</td>\n","      <td>OH</td>\n","      <td>19.03</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>10740</td>\n","      <td>40.4</td>\n","      <td>21.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>PC3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>MORTGAGE</td>\n","      <td>66250.0</td>\n","      <td>VERIFIED - income</td>\n","      <td>n</td>\n","      <td>wedding</td>\n","      <td>014xx</td>\n","      <td>MA</td>\n","      <td>9.40</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>3656</td>\n","      <td>24.1</td>\n","      <td>10.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>PC3</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>RENT</td>\n","      <td>26000.0</td>\n","      <td>VERIFIED - income source</td>\n","      <td>n</td>\n","      <td>debt consolidation</td>\n","      <td>112xx</td>\n","      <td>NY</td>\n","      <td>20.49</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>6709</td>\n","      <td>58.9</td>\n","      <td>12.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>PC3</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>RENT</td>\n","      <td>47831.0</td>\n","      <td>not verified</td>\n","      <td>n</td>\n","      <td>debt consolidation</td>\n","      <td>070xx</td>\n","      <td>NJ</td>\n","      <td>24.13</td>\n","      <td>...</td>\n","      <td>111.0</td>\n","      <td>9.0</td>\n","      <td>1.0</td>\n","      <td>11346</td>\n","      <td>60.7</td>\n","      <td>17.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>3</td>\n","      <td>PC3</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>MORTGAGE</td>\n","      <td>70000.0</td>\n","      <td>not verified</td>\n","      <td>n</td>\n","      <td>major purchase</td>\n","      <td>244xx</td>\n","      <td>VA</td>\n","      <td>16.18</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>17157</td>\n","      <td>50.9</td>\n","      <td>27.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>PC3</td>\n","    </tr>\n","    <tr>\n","      <th>10000</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>RENT</td>\n","      <td>70560.0</td>\n","      <td>not verified</td>\n","      <td>n</td>\n","      <td>credit card</td>\n","      <td>900xx</td>\n","      <td>CA</td>\n","      <td>16.13</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>15.0</td>\n","      <td>0.0</td>\n","      <td>2304</td>\n","      <td>22.6</td>\n","      <td>34.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>PC5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows Ã— 23 columns</p>\n","</div>"],"text/plain":["       is_bad emp_length home_ownership annual_inc       verification_status  \\\n","Id                                                                             \n","1           0         10       MORTGAGE        NaN              not verified   \n","2           0          1           RENT        NaN              not verified   \n","3           0          4           RENT        NaN              not verified   \n","4           0         10       MORTGAGE        NaN              not verified   \n","5           0         10       MORTGAGE        NaN         VERIFIED - income   \n","...       ...        ...            ...        ...                       ...   \n","9996        0          5       MORTGAGE    66250.0         VERIFIED - income   \n","9997        0          1           RENT    26000.0  VERIFIED - income source   \n","9998        0          8           RENT    47831.0              not verified   \n","9999        0          6       MORTGAGE    70000.0              not verified   \n","10000       0          1           RENT    70560.0              not verified   \n","\n","      pymnt_plan         purpose_cat zip_code addr_state  debt_to_income  ...  \\\n","Id                                                                        ...   \n","1              n             medical    766xx         TX           10.87  ...   \n","2              n  debt consolidation    660xx         KS            9.15  ...   \n","3              n         credit card    916xx         CA           11.24  ...   \n","4              n  debt consolidation    124xx         NY            6.18  ...   \n","5              n  debt consolidation    439xx         OH           19.03  ...   \n","...          ...                 ...      ...        ...             ...  ...   \n","9996           n             wedding    014xx         MA            9.40  ...   \n","9997           n  debt consolidation    112xx         NY           20.49  ...   \n","9998           n  debt consolidation    070xx         NJ           24.13  ...   \n","9999           n      major purchase    244xx         VA           16.18  ...   \n","10000          n         credit card    900xx         CA           16.13  ...   \n","\n","       mths_since_last_record  open_acc  pub_rec  revol_bal  revol_util  \\\n","Id                                                                        \n","1                         NaN      15.0      0.0      12087        12.1   \n","2                         NaN       4.0      0.0      10114        64.0   \n","3                         NaN       4.0      0.0         81         0.6   \n","4                         NaN       6.0      0.0      10030        37.1   \n","5                         NaN       8.0      0.0      10740        40.4   \n","...                       ...       ...      ...        ...         ...   \n","9996                      NaN       8.0      0.0       3656        24.1   \n","9997                      NaN       8.0      0.0       6709        58.9   \n","9998                    111.0       9.0      1.0      11346        60.7   \n","9999                      NaN       9.0      0.0      17157        50.9   \n","10000                     NaN      15.0      0.0       2304        22.6   \n","\n","       total_acc  initial_list_status  collections_12_mths_ex_med  \\\n","Id                                                                  \n","1           44.0                    f                         0.0   \n","2            5.0                    f                         0.0   \n","3            8.0                    f                         0.0   \n","4           23.0                    f                         0.0   \n","5           21.0                    f                         0.0   \n","...          ...                  ...                         ...   \n","9996        10.0                    f                         0.0   \n","9997        12.0                    f                         0.0   \n","9998        17.0                    f                         0.0   \n","9999        27.0                    f                         0.0   \n","10000       34.0                    f                         0.0   \n","\n","       mths_since_last_major_derog policy_code  \n","Id                                              \n","1                                1         PC4  \n","2                                2         PC1  \n","3                                3         PC4  \n","4                                2         PC2  \n","5                                3         PC3  \n","...                            ...         ...  \n","9996                             2         PC3  \n","9997                             2         PC3  \n","9998                             3         PC3  \n","9999                             2         PC3  \n","10000                            2         PC5  \n","\n","[10000 rows x 23 columns]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["test_lend_data = lending_data.copy()\n","test_lend_data['annual_inc'][0:5] = pd.NA\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":4}
